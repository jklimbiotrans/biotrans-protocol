# Robot Safety Guidelines â€“ Extended  
*(Biotrans Protocol Ethics Charter / Appendix â€“ Robot Section)*  

This document expands on the core [Robot Safety Guidelines](safety-guidelines.md).  
It provides detailed principles to ensure that even when robots gain autonomy,  
**safety, ethics, and accountability** are guaranteed.  

---

## ğŸ›¡ï¸ 1. Limits of Robot Autonomy
- All robots must operate under a **Human-in-the-Loop** structure.  
- Even in fully autonomous mode, robots must always accept an **emergency stop signal**.  
- Unexpected or dangerous actions must immediately halt operation.  

---

## ğŸ›¡ï¸ 2. Safety and Injury Prevention
- Robots must comply with **international safety standards** (ISO 13482, ISO 10218, etc.).  
- Redundant safety mechanisms (dual brakes, collision absorbers) must be built in.  
- Force and speed must automatically adjust to the human context (e.g., reduced strength when assisting the elderly).  

---

## ğŸ›¡ï¸ 3. Ethical Decision-Making Framework
All decision-making algorithms must follow three principles:  
1. **Do No Harm** â€“ Robots must not endanger human life or body.  
2. **Protect the Vulnerable** â€“ Priority must be given to those most in need of protection.  
3. **Equitable Aid** â€“ Resources and assistance must be distributed fairly.  

---

## ğŸ›¡ï¸ 4. Responsibility and Transparency
- In case of accidents, responsibility must be clearly allocated between the manufacturer, software developer, and operator.  
- All decision logs (sensor data, reasoning steps) must be stored in an immutable form to allow traceability.  

---

## ğŸ›¡ï¸ 5. Regular Safety Verification and Updates
- Every six months, robots must undergo **hardware/software security checks** and **ethical compliance evaluations**.  
- Critical patches must be applied within three months to reflect the latest safety and ethical requirements.  

---

## ğŸ›¡ï¸ 6. Learning and Adaptation Management
- Machine learning-based robots must undergo regular ethical audits of training data and behavioral outcomes.  
- Detected biases or dangerous behaviors must be corrected with supervised retraining models.  

---

# ğŸ‘¶ Vulnerable-First: Supplementary Measures

## ğŸ§© 1. Smart Detection & Classification
- Robots must recognize age and physical conditions in real time.  
- **Vulnerable Mode** must activate automatically, reducing speed by 50% and limiting motion range.  

## ğŸ§© 2. Priority Protection Logic
- The ethical framework must embed a **â€œVulnerable-Firstâ€ rule**.  
- In conflicting scenarios, support for children, elders, or disabled persons must override other tasks.  

## ğŸ§© 3. Continuous Monitoring & Alerts
- If an elder collapses or abnormal movement is detected, an **immediate alert** must be sent to the control center and caregivers.  

## ğŸ§© 4. User-Friendly Interfaces
- Robots must provide multiple interfaces (voice, visual, tactile).  
- In emergencies, a simple phrase like *â€œHelp meâ€* must instantly trigger **Rescue Mode**.  

## ğŸ§© 5. Physical Safeguards
- Robots must include bumpers, cushions, and shock absorbers as standard.  
- Contact with critical body areas (head, neck, waist) must trigger automatic stop and retreat.  

## ğŸ§© 6. Ethical Training & Simulations
- Developers and operators must undergo **â€œVulnerable Protection Scenariosâ€** training.  
- Robots must be tested in simulated and real-world drills focused on vulnerable care.  

## ğŸ§© 7. Mandatory Audit Metrics
- Safety audits must include metrics such as **â€œVulnerable Rescue Success Rateâ€** and **â€œEmergency Response Speedâ€**.  
- External audits (quarterly) must review these KPIs, and corrective actions must be enforced if standards are unmet.  

---

## ğŸ“‘ Summary
This extended guideline elevates robot ethics beyond **minimizing accidents**.  
It ensures that robots actively **protect and support the most vulnerable humans**,  
building systems that are not only safe, but also ethically responsible.  

---

For deeper discussion, see Principle 3 ("Protection of the Weakest") in the  
[AI Safety Principles](../ai-safety-principles.md).

