# Robot Safety Guidelines – Extended  
*(Biotrans Protocol Ethics Charter / Appendix – Robot Section)*  

This document expands on the core [Robot Safety Guidelines](safety-guidelines.md).  
It provides detailed principles to ensure that even when robots gain autonomy,  
**safety, ethics, and accountability** are guaranteed.  

---

## 🛡️ 1. Limits of Robot Autonomy
- All robots must operate under a **Human-in-the-Loop** structure.  
- Even in fully autonomous mode, robots must always accept an **emergency stop signal**.  
- Unexpected or dangerous actions must immediately halt operation.  

---

## 🛡️ 2. Safety and Injury Prevention
- Robots must comply with **international safety standards** (ISO 13482, ISO 10218, etc.).  
- Redundant safety mechanisms (dual brakes, collision absorbers) must be built in.  
- Force and speed must automatically adjust to the human context (e.g., reduced strength when assisting the elderly).  

---

## 🛡️ 3. Ethical Decision-Making Framework
All decision-making algorithms must follow three principles:  
1. **Do No Harm** – Robots must not endanger human life or body.  
2. **Protect the Vulnerable** – Priority must be given to those most in need of protection.  
3. **Equitable Aid** – Resources and assistance must be distributed fairly.  

---

## 🛡️ 4. Responsibility and Transparency
- In case of accidents, responsibility must be clearly allocated between the manufacturer, software developer, and operator.  
- All decision logs (sensor data, reasoning steps) must be stored in an immutable form to allow traceability.  

---

## 🛡️ 5. Regular Safety Verification and Updates
- Every six months, robots must undergo **hardware/software security checks** and **ethical compliance evaluations**.  
- Critical patches must be applied within three months to reflect the latest safety and ethical requirements.  

---

## 🛡️ 6. Learning and Adaptation Management
- Machine learning-based robots must undergo regular ethical audits of training data and behavioral outcomes.  
- Detected biases or dangerous behaviors must be corrected with supervised retraining models.  

---

# 👶 Vulnerable-First: Supplementary Measures

## 🧩 1. Smart Detection & Classification
- Robots must recognize age and physical conditions in real time.  
- **Vulnerable Mode** must activate automatically, reducing speed by 50% and limiting motion range.  

## 🧩 2. Priority Protection Logic
- The ethical framework must embed a **“Vulnerable-First” rule**.  
- In conflicting scenarios, support for children, elders, or disabled persons must override other tasks.  

## 🧩 3. Continuous Monitoring & Alerts
- If an elder collapses or abnormal movement is detected, an **immediate alert** must be sent to the control center and caregivers.  

## 🧩 4. User-Friendly Interfaces
- Robots must provide multiple interfaces (voice, visual, tactile).  
- In emergencies, a simple phrase like *“Help me”* must instantly trigger **Rescue Mode**.  

## 🧩 5. Physical Safeguards
- Robots must include bumpers, cushions, and shock absorbers as standard.  
- Contact with critical body areas (head, neck, waist) must trigger automatic stop and retreat.  

## 🧩 6. Ethical Training & Simulations
- Developers and operators must undergo **“Vulnerable Protection Scenarios”** training.  
- Robots must be tested in simulated and real-world drills focused on vulnerable care.  

## 🧩 7. Mandatory Audit Metrics
- Safety audits must include metrics such as **“Vulnerable Rescue Success Rate”** and **“Emergency Response Speed”**.  
- External audits (quarterly) must review these KPIs, and corrective actions must be enforced if standards are unmet.  

---

## 📑 Summary
This extended guideline elevates robot ethics beyond **minimizing accidents**.  
It ensures that robots actively **protect and support the most vulnerable humans**,  
building systems that are not only safe, but also ethically responsible.  

---

For deeper discussion, see Principle 3 ("Protection of the Weakest") in the  
[AI Safety Principles](../ai-safety-principles.md).

